{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c8adbc-236b-4a77-aa76-0469ef0195b5",
      "metadata": {
        "language": "python",
        "name": "imports",
        "title": "imports"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.ml.registry import Registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc41b720-843a-4d12-aa4f-4b05d9be3f0e",
      "metadata": {
        "language": "python",
        "name": "session",
        "title": "session"
      },
      "outputs": [],
      "source": [
        "session = Session.get_active_session()\n",
        "if session is None:\n",
        "    connection_name = os.getenv(\"SNOWFLAKE_DEFAULT_CONNECTION_NAME\", \"default\")\n",
        "    session = Session.SessionBuilder().configs({\"connection_name\": connection_name}).create()\n",
        "session.use_database(\"POC\")\n",
        "session.use_schema(\"CHURN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4aa241-225a-47c0-b80b-53ef737549db",
      "metadata": {
        "language": "python",
        "name": "pipeline",
        "title": "pipeline"
      },
      "outputs": [],
      "source": [
        "# 1. Get Snowflake session and load training data\n",
        "df_raw = session.table(\"CUSTOMER_CHURN\").limit(5000).to_pandas().dropna()\n",
        "df = df_raw.copy()  # Preserve raw for post-inference join\n",
        "\n",
        "# 2. Encode 'GENDER' using LabelEncoder\n",
        "le_gender = LabelEncoder()\n",
        "df['GENDER'] = le_gender.fit_transform(df['GENDER'])\n",
        "\n",
        "# 3. Define features and target\n",
        "target_col = 'CHURN'\n",
        "id_col = 'CUSTOMERID'\n",
        "X = df.drop(columns=[target_col, id_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Define feature types\n",
        "categorical_ohe = ['SUBSCRIPTION_TYPE']\n",
        "categorical_ord = ['CONTRACT_LENGTH']\n",
        "numeric_features = [col for col in X.columns if col not in categorical_ohe + categorical_ord + ['GENDER']]\n",
        "\n",
        "# 6. Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_ohe),\n",
        "    ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical_ord),\n",
        "    ('gender', 'passthrough', ['GENDER']),\n",
        "    ('numeric', 'passthrough', numeric_features)\n",
        "])\n",
        "\n",
        "# 7. Model pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef2d005-bace-4a73-9abe-fb1fcaeb945e",
      "metadata": {
        "language": "python",
        "name": "train",
        "title": "train"
      },
      "outputs": [],
      "source": [
        "# 8. Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'classifier__n_estimators': [100, 200],\n",
        "    'classifier__max_depth': [10, 20, None],\n",
        "    'classifier__min_samples_split': [2, 5],\n",
        "    'classifier__min_samples_leaf': [1, 2],\n",
        "    'classifier__max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    pipeline,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 9. Train and select best model\n",
        "search.fit(X_train, y_train)\n",
        "best_model = search.best_estimator_\n",
        "\n",
        "# 10. Register model to Snowflake Model Registry\n",
        "reg = Registry(session=session)\n",
        "model_name = \"RANDOM_FOREST\"\n",
        "model_version = \"V_8\"\n",
        "\n",
        "logged_model = reg.log_model(\n",
        "    model_name=model_name,\n",
        "    version_name=model_version,\n",
        "    model=best_model,\n",
        "    sample_input_data=X_train.head(100),\n",
        "    target_platforms=[\"WAREHOUSE\"],\n",
        "    options={\"enable_explainability\": True}\n",
        ")\n",
        "\n",
        "reg.show_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d8bf5c4-ca07-4209-a115-9adcfd89af83",
      "metadata": {
        "language": "python",
        "name": "cross_test",
        "title": "cross_test"
      },
      "outputs": [],
      "source": [
        "# ──────────────────────────────────────────────\n",
        "# 11. Run inference on X_test using model registry\n",
        "# ──────────────────────────────────────────────\n",
        "\n",
        "model_ver = reg.get_model(model_name).version(model_version)\n",
        "\n",
        "# Inference\n",
        "pred_df = model_ver.run(X_test, function_name=\"predict\").rename(\n",
        "    columns={\"output_feature_0\": \"CHURN_PREDICTION\"}\n",
        ")\n",
        "prob_df = model_ver.run(X_test, function_name=\"predict_proba\")[[\"output_feature_1\"]].rename(\n",
        "    columns={\"output_feature_1\": \"CHURN_PREDICTION_PROB\"}\n",
        ")\n",
        "explain_df = model_ver.run(X_test, function_name=\"explain\")\n",
        "\n",
        "# ──────────────────────────────────────────────\n",
        "# 12. Combine original raw test data with predictions\n",
        "# ──────────────────────────────────────────────\n",
        "\n",
        "# Get full original rows corresponding to test set\n",
        "raw_test_df = df_raw.loc[X_test.index].reset_index(drop=True)  # Includes CUSTOMERID and raw GENDER\n",
        "\n",
        "# Combine everything into final_df\n",
        "final_df = pd.concat([\n",
        "    raw_test_df,\n",
        "    pred_df.reset_index(drop=True),\n",
        "    prob_df.reset_index(drop=True),\n",
        "    explain_df.reset_index(drop=True)\n",
        "], axis=1)\n",
        "\n",
        "# Add actual label\n",
        "final_df[\"CHURN\"] = y_test.reset_index(drop=True)\n",
        "\n",
        "# Evaluation\n",
        "print(f\"\\n✅ ROC AUC on test data: {roc_auc_score(final_df['CHURN'], final_df['CHURN_PREDICTION_PROB']):.4f}\")\n",
        "print(\"✅ Model Classification Report:\\n\", classification_report(final_df['CHURN'], final_df['CHURN_PREDICTION']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e393f80",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef6928b9-152c-43d1-94d3-46519ad4a3cb",
      "metadata": {
        "codeCollapsed": false,
        "language": "python",
        "name": "cell1"
      },
      "outputs": [],
      "source": [
        "#Save final_df from above into a snowflake table so we can plug it into Snowflake Intelligence by creating a semantic view on top of it\n",
        "final_df_snowpark = session.create_dataframe(final_df)\n",
        "final_df_snowpark.write.mode(\"overwrite\").save_as_table(\"CHURN_DATA_EXPLANATIONS\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.12.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "lastEditStatus": {
      "authorEmail": "sukanya.joshi@snowflake.com",
      "authorId": "47121975279",
      "authorName": "SUJOSHI",
      "lastEditTime": 1760549163847,
      "notebookId": "7qqrkuk7775wuecgolrm",
      "sessionId": "f2379568-f3e0-457c-90a5-feea49749881"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
